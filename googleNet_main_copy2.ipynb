{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import re\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple, List, Callable, Any\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$output\\_shape = \\frac{input\\_shape + 2{\\times}padding - dilation{\\times}(kernel\\_size - 1) - 1}{stride} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9556de0660c5>:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  self.mDataX = torch.permute(torch.tensor(self.mDataX), (0,3,1,2))\n"
     ]
    }
   ],
   "source": [
    "class path_1(Dataset):\n",
    "\n",
    "    def __init__(self, root_path):\n",
    "        self.mDataX = []\n",
    "        self.mDataY = []\n",
    "\n",
    "        for img_path in glob.glob(root_path + r'/*'):\n",
    "            img = Image.open(img_path)\n",
    "            img_data = np.array(img, dtype = float)/255\n",
    "            #img_data = img_data[np.newaxis,:,:]\n",
    "            #img_data = img_data.reshape(-1)\n",
    "            self.mDataX.append(img_data)\n",
    "            pattern = '[/\\\\\\.]'\n",
    "            img_na = re.split(pattern, img_path)[-2]\n",
    "            \n",
    "            if list(img_na)[-1] == 'T':\n",
    "                self.mDataY.append([1])\n",
    "            elif list(img_na)[-1] == 'F':\n",
    "                self.mDataY.append([0])\n",
    "    \n",
    "        self.mDataX = torch.permute(torch.tensor(self.mDataX), (0,3,1,2))\n",
    "        self.mDataY = torch.tensor(self.mDataY)\n",
    "        \n",
    "    def __getitem__(self, data_index):\n",
    "        input_tensor = torch.tensor(self.mDataX[data_index])\n",
    "        output_tensor = torch.tensor(self.mDataY[data_index])\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mDataX)\n",
    "\n",
    "#train_set = path_1(r'/Users/wz/OneDrive/OneDrive - Kyoto University/Project/Yuyake_recog/pro_set') #Mac\n",
    "train_set = path_1(r'C:/Users/yaoho/OneDrive - Kyoto University/Project/Yuyake_recog/pro_set') #Win\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 1, shuffle = True, num_workers = 0)  # , num_workers=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n",
      "torch.Size([1, 3, 329, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-c9293b050e94>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(self.mDataX[data_index])\n",
      "<ipython-input-7-c9293b050e94>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_tensor = torch.tensor(self.mDataY[data_index])\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_loader:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set = path_1(r'/Users/wz/OneDrive/OneDrive - Kyoto University/Project/Yuyake_recog/test_set') #Mac\n",
    "test_set = path_1(r'C:/Users/yaoho/OneDrive - Kyoto University/Project/Yuyake_recog/test_set') #Win\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)#bias=False\n",
    "        self.bn = torch.nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class Inception(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int,\n",
    "        ch1x1: int,\n",
    "        ch3x3red: int,\n",
    "        ch3x3: int,\n",
    "        ch5x5red: int,\n",
    "        ch5x5: int,\n",
    "        pool_proj: int,\n",
    "        conv_block: Optional[Callable[..., torch.nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size = 1)\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, ch3x3red, kernel_size=1), \n",
    "            conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
    "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
    "            conv_block(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "    \n",
    "    \n",
    "class googleNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                dropout = 0.2,\n",
    "                num_classes = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = BasicConv2d(3, 64, kernel_size=5, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        self.conv2 = BasicConv2d(64, 64, kernel_size=1)\n",
    "        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        \n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        \n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "        \n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "    \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(1024, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 16)\n",
    "        self.fc3 = torch.nn.Linear(16, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.maxpool1(self.conv1(x))\n",
    "        x = self.conv3(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        \n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        \n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(batch_size, -1)#flatten\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "def train(epoch):\n",
    "    loss_val = []\n",
    "    running_loss = 0.\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader, 0):#minibatch..\n",
    "        reg = 0.\n",
    "        inputs, labels = data#scalar X, Y\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        optimizer.zero_grad()#optimizer RESET\n",
    "\n",
    "        #forward #backward\n",
    "        outputs = model(inputs)\n",
    "        #for params in model.parameters():\n",
    "            #reg += 0.5 * (params ** 2).sum()\n",
    "        loss = criterion(outputs, labels) + 0.7 * reg\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        loss_val.append(running_loss)\n",
    "        if batch_idx % len(train_set) == len(train_set) - 1 and epoch % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, batch_idx+1, running_loss))\n",
    "            running_loss = 0.\n",
    "        if batch_idx % len(train_set) == len(train_set) - 1 and epoch == 999:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, batch_idx+1, running_loss))\n",
    "            running_loss = 0.\n",
    "    return np.mean(loss_val) \n",
    "\n",
    "def test():\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.float()\n",
    "            labels = labels.float()\n",
    "            outputs = model(images)\n",
    "            predicted, _ = torch.max(outputs.data, dim = 1)\n",
    "            #total += torch.squeeze(labels)\n",
    "            predicted = torch.squeeze(predicted)\n",
    "            correct += (torch.round(predicted) == labels).sum().item()\n",
    "            print(f'predict:{torch.round(predicted)}\\nTrue label:{labels}')\n",
    "    print('Accuracy on test set: %d %%' % (100 * correct / len(test_set)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9556de0660c5>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(self.mDataX[data_index])\n",
      "<ipython-input-2-9556de0660c5>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_tensor = torch.tensor(self.mDataY[data_index])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   149] loss: 103.223\n",
      "[101,   149] loss: 0.046\n",
      "[201,   149] loss: 0.011\n"
     ]
    }
   ],
   "source": [
    "#Training process\n",
    "model = googleNet()\n",
    "criterion = torch.nn.BCELoss(size_average = True)#??##?_?\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.00075, momentum = 0.9)\n",
    "#optimizer = optim.Adam(model.parameters(), lr = 0.0075)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.96)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loss_curv = []\n",
    "    for epoch in range(1000):\n",
    "        #train(epoch)\n",
    "        loss_val = train(epoch)\n",
    "        loss_curv.append(loss_val)\n",
    "        scheduler.step()\n",
    "    plt.plot(loss_curv)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.save(model.state_dict(), \n",
    "           'C:/Users/yaoho/OneDrive - Kyoto University/Project/Yuyake_recog/models_cache/googlenet_decay1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:0.0\n",
      "True label:tensor([[0.]])\n",
      "predict:1.0\n",
      "True label:tensor([[0.]])\n",
      "predict:0.0\n",
      "True label:tensor([[0.]])\n",
      "predict:1.0\n",
      "True label:tensor([[1.]])\n",
      "predict:1.0\n",
      "True label:tensor([[1.]])\n",
      "Accuracy on test set: 80 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9556de0660c5>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(self.mDataX[data_index])\n",
      "<ipython-input-2-9556de0660c5>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_tensor = torch.tensor(self.mDataY[data_index])\n"
     ]
    }
   ],
   "source": [
    "#testing process\n",
    "PATH = 'C:/Users/yaoho/OneDrive - Kyoto University/Project/Yuyake_recog/models_cache/googlenet_decay1.pth'\n",
    "model = googleNet()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
