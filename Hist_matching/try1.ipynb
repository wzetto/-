{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from rembg import remove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoise step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.imread('./test/Castoria_002.jpg')\n",
    "sav_pth = './test/Castoria_002_deno.jpg'\n",
    "# output = output[1732-1142:-1, :] #* Cropping step.\n",
    "h = 10\n",
    "#* Size in pixels of the template patch that is used to compute weights. Should be odd. Recommended value 7 pixels\n",
    "templateWindowSize = 7\n",
    "#* Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater denoising time. Recommended value 21 pixels\n",
    "searchWindowSize = 21\n",
    "output_ = cv2.fastNlMeansDenoisingColored(output, None, h, h, templateWindowSize, searchWindowSize)\n",
    "cv2.imwrite(sav_pth, output_)\n",
    "\n",
    "cv2.imshow('output_1', output_)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutout step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './test/Castoria_002_deno.jpg'\n",
    "output_path = './test/Castoria_002_deno_cutout.jpg'\n",
    "\n",
    "with open(input_path, 'rb') as i:\n",
    "    with open(output_path, 'wb') as o:\n",
    "        input = i.read()\n",
    "        output = remove(input)\n",
    "        o.write(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram equilization + matching step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth_raw = './test/Castoria_002_deno_cutout.jpg'\n",
    "pth_ref = './test/reference_raw.png'\n",
    "pth_out = './test/hist_match.jpg'\n",
    "\n",
    "img_raw = cv2.imread(pth_raw)\n",
    "\n",
    "img_ref =  cv2.imread(pth_ref)\n",
    "img_raw_ = img_raw.copy()\n",
    "\n",
    "def hist_match(img_raw, referensi):\n",
    "\n",
    "    img_raw_shape = img_raw.shape\n",
    "    \n",
    "    img_raw = img_raw.flatten()\n",
    "    referensi = referensi.flatten()\n",
    "\n",
    "    o_values, bin_idx, o_counts = np.unique(img_raw, return_inverse=True,return_counts=True)\n",
    "    b_values, b_counts = np.unique(referensi, return_counts=True)\n",
    "\n",
    "    o_quantiles = np.cumsum(o_counts).astype(np.float64) #* Cumulative sum\n",
    "    o_quantiles /= o_quantiles[-1] #* Normalization\n",
    "    b_quantiles = np.cumsum(b_counts).astype(np.float64)\n",
    "    b_quantiles /= b_quantiles[-1]\n",
    "\n",
    "    interp_t_values = np.interp(o_quantiles, b_quantiles, b_values)\n",
    "\n",
    "    #* [bin_idx] expand the unique array into the original shape.\n",
    "    return interp_t_values[bin_idx].reshape(img_raw_shape)\n",
    "\n",
    "for i in range(3):\n",
    "    img_raw[:,:,i] = hist_match(img_raw[:,:,i], img_ref[:,:,i])\n",
    "\n",
    "cv2.imwrite(pth_out, img_ref)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual-denoise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.imread('./test/hist_match.jpg')\n",
    "sav_pth = './test/hist_match_deno.png'\n",
    "h = 3\n",
    "#* Size in pixels of the template patch that is used to compute weights. Should be odd. Recommended value 7 pixels\n",
    "templateWindowSize = 7\n",
    "#* Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater denoising time. Recommended value 21 pixels\n",
    "searchWindowSize = 21\n",
    "output_ = cv2.fastNlMeansDenoisingColored(output, None, h, h, templateWindowSize, searchWindowSize)\n",
    "cv2.imwrite(sav_pth, output_)\n",
    "\n",
    "cv2.imshow('output_1', output_)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread('./test/Castoria_002_deno_cutout.jpg')\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "# Apply a threshold to the grayscale image\n",
    "_, threshold = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)\n",
    "t_x, t_y = np.where(threshold==0)\n",
    "t_ind = np.concatenate((t_x.reshape(-1,1), t_y.reshape(-1,1)), axis=1) #* Return transparent coordinates.\n",
    "\n",
    "new = cv2.imread('./test/hist_match_deno.png')\n",
    "new = cv2.cvtColor(new, cv2.COLOR_BGR2RGBA)\n",
    "sav_new = './test/hist_match_deno_cutout.png'\n",
    "alpha = new[:, :, 3]\n",
    "alpha[t_x, t_y] = 0\n",
    "new[:, :, 3] = alpha\n",
    "new = cv2.cvtColor(new, cv2.COLOR_RGBA2BGRA)\n",
    "\n",
    "cv2.imwrite(sav_new, new)\n",
    "\n",
    "cv2.imshow('inpaint', new)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
